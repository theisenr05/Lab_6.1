{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e97470",
   "metadata": {},
   "source": [
    "# Lab 6.1 — Summarizing the Healthcare Survey with PySpark\n",
    "\n",
    "This Colab notebook implements the required transformation steps using **PySpark** (no `melt`).  \n",
    "It reads the `_v2` files (dots replaced by underscores), reshapes with `stack`, joins reverse-coding metadata, recodes values (including reverse-coded items), aggregates per-feature scores, and writes `health_survey_summary.csv` to the `data/` folder.\n",
    "\n",
    "**Files included in `/content/data`:**\n",
    "- `health_survey_v2.csv` — survey responses\n",
    "- `ReverseCodingItems_v2.csv` — reverse-coding metadata\n",
    "- `health_survey_summary.csv` — final produced summary (also produced by this notebook if you run it)\n",
    "\n",
    "Follow the instructions and run cells sequentially. Screenshots placeholders are provided where your instructor requests them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and start PySpark if running in Colab (uncomment when in Colab)\n",
    "# !apt-get install -y openjdk-11-jdk-headless -qq > /dev/null\n",
    "# !pip install -q pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.master(\"local[*]\").appName(\"Lab6_1\").getOrCreate()\n",
    "\n",
    "# Files are expected under /content/data\n",
    "import os\n",
    "print('Files in /content/data:')\n",
    "print(os.listdir('/content/data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db82b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PySpark code (run this in Colab after installing pyspark) ===\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col, when, create_map, lit, regexp_extract\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Lab6_1').getOrCreate()\n",
    "\n",
    "survey = spark.read.csv('/content/data/health_survey_v2.csv', header=True, inferSchema=True)\n",
    "reverse = spark.read.csv('/content/data/ReverseCodingItems_v2.csv', header=True, inferSchema=True)\n",
    "\n",
    "# show top rows\n",
    "survey.show(5, truncate=False)\n",
    "reverse.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Identify question columns (all except ID)\n",
    "question_cols = [c for c in survey.columns if c != 'ID']\n",
    "print('Question columns (count={}):'.format(len(question_cols)), question_cols)\n",
    "\n",
    "# 2) Build stack expression and reshape to long\n",
    "stack_expr = \"stack({}, {})\".format(len(question_cols), \", \".join([f\"'{c}', `{c}`\" for c in question_cols]))\n",
    "long_df = survey.select(col('ID'), expr(stack_expr).alias('Question','Response'))\n",
    "long_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8902c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Join with reverse coding info\n",
    "reverse_small = reverse.select(col('Column Name').alias('Question'), col('Needs Reverse Coding?').alias('NeedsReverse'))\n",
    "joined = long_df.join(reverse_small, on='Question', how='left').fillna({'NeedsReverse':'No'})\n",
    "\n",
    "# 4) Create normal and reverse coded values using when()\n",
    "coded = joined.withColumn('Temp_Normal',\n",
    "    when(col('Response')=='Strongly Disagree', 1)\n",
    "    .when(col('Response')=='Somewhat Disagree', 2)\n",
    "    .when(col('Response')=='Neither Agree nor Disagree', 3)\n",
    "    .when(col('Response')=='Somewhat Agree', 4)\n",
    "    .when(col('Response')=='Strongly Agree', 5)\n",
    "    .otherwise(None)\n",
    ").withColumn('Temp_Reverse',\n",
    "    when(col('Response')=='Strongly Disagree', 5)\n",
    "    .when(col('Response')=='Somewhat Disagree', 4)\n",
    "    .when(col('Response')=='Neither Agree nor Disagree', 3)\n",
    "    .when(col('Response')=='Somewhat Agree', 2)\n",
    "    .when(col('Response')=='Strongly Agree', 1)\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# 5) Final recoded value based on NeedsReverse\n",
    "coded = coded.withColumn('RecodedValue', when(col('NeedsReverse')=='Yes', col('Temp_Reverse')).otherwise(col('Temp_Normal')))\n",
    "\n",
    "# 6) Extract Feature prefix (F1..F6)\n",
    "coded = coded.withColumn('Feature', regexp_extract(col('Question'), r'^(F\\d+)', 0))\n",
    "\n",
    "coded.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41690b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Aggregate mean RecodedValue per ID per Feature and pivot wide\n",
    "summary = coded.groupBy('ID','Feature').avg('RecodedValue').withColumnRenamed('avg(RecodedValue)','MeanScore')\n",
    "final = summary.groupBy('ID').pivot('Feature', ['F1','F2','F3','F4','F5','F6']).agg({'MeanScore':'first'}).orderBy('ID')\n",
    "\n",
    "final.show(20, truncate=False)\n",
    "\n",
    "# 8) Write result to CSV\n",
    "final.coalesce(1).write.csv('/content/data/health_survey_summary_pyspark.csv', header=True, mode='overwrite')\n",
    "print('Written /content/data/health_survey_summary_pyspark.csv (folder with part files)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d7a6ab",
   "metadata": {},
   "source": [
    "## Screenshots to include in your worksheet\n",
    "\n",
    "1. **Loading data** — screenshot the cell output that lists files and `survey.show()`.\n",
    "2. **Stack using `stack()`** — screenshot the long format `long_df.show()` output.\n",
    "3. **Joined dataset** — screenshot `joined.show()` or `coded.show()` showing NeedsReverse and Temp columns.\n",
    "4. **Coded columns** — screenshot the `RecodedValue` column.\n",
    "5. **Aggregated final result** — screenshot the `final.show()` output.\n",
    "\n",
    "Place each screenshot in your worksheet as required by the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39748245",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- This notebook is written for Colab. Uncomment the pip/apt install lines at the top to install pyspark before running.\n",
    "- The small CSV `health_survey_summary.csv` was produced by pandas in this environment and saved to `/mnt/data/data/health_survey_summary.csv` for quick download and verification.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
